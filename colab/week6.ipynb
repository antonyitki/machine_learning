{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOksSj+sGDp9FRefEEAaHSU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["**\"more about NN\"**"],"metadata":{"id":"OKure56EmwDF"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"SyIETZMRq0Be","executionInfo":{"status":"ok","timestamp":1667386239657,"user_tz":0,"elapsed":295,"user":{"displayName":"Tony Cash","userId":"15357384119899770783"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import datetime as dt\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense , Dropout, LSTM\n","\n","florida = pd.read_csv(\"/content/florida.csv\")\n","florida.head()\n","florida.tail(5)\n","florida[\"Date\"] = pd.to_datetime(florida[\"Date\"])\n","\n","florida = florida[[\"Date\",\"Avg_Temp\"]]\n","# florida = florida[\"Avg_Temp\"].resample(\"MS\").mean()\n","florida = florida.fillna(florida.bfill())\n","florida.columns = [\"Date\", \"Avg_Temp\"]\n","\n","train = florida[:-225]\n","len(train)\n","test = florida[-255:]\n","len(test)\n","train_dates = pd.to_datetime(train[\"Date\"])\n","test_dates = pd.to_datetime(test[\"Date\"])"]},{"cell_type":"code","source":["scaler = MinMaxScaler(feature_range = (0,1))\n","scaled_data = scaler.fit_transform(train[\"Avg_Temp\"]. values.reshape(-1, 1))\n","prediction_days = 225\n","x_train = []\n","y_train = []\n","\n","for x in range(prediction_days, len(scaled_data)):\n","  x_train.append(scaled_data[x-prediction_days:x, 0])\n","  y_train.append(scaled_data[x, 0])\n","\n","x_train, y_train = np.array(x_train), np.array(y_train)\n","x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"],"metadata":{"id":"OQ-2Ak8ZpeP9","executionInfo":{"status":"ok","timestamp":1667386239935,"user_tz":0,"elapsed":6,"user":{"displayName":"Tony Cash","userId":"15357384119899770783"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(LSTM(units = 128, activation = 'relu', return_sequences=True, input_shape = (x_train.shape[1], 1)))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units = 128, activation = 'relu', return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units = 128, activation = 'relu', return_sequences=False))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRmKGN5i1ZQv","executionInfo":{"status":"ok","timestamp":1667386242544,"user_tz":0,"elapsed":2613,"user":{"displayName":"Tony Cash","userId":"15357384119899770783"}},"outputId":"e3fad301-614d-4472-f825-acf1c9a65ebd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","source":["model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-uD5nNuY2eSx","executionInfo":{"status":"ok","timestamp":1667386242545,"user_tz":0,"elapsed":13,"user":{"displayName":"Tony Cash","userId":"15357384119899770783"}},"outputId":"72fa741b-f03b-4805-b3fa-366940e1e829"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 225, 128)          66560     \n","                                                                 \n"," dropout (Dropout)           (None, 225, 128)          0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 225, 128)          131584    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 225, 128)          0         \n","                                                                 \n"," lstm_2 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 329,857\n","Trainable params: 329,857\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='mean_squared_error')\n","model.summary()\n","\n","history = model.fit(x_train, y_train, epochs = 25, batch_size=32, validation_split=0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jsKqU6L63wmE","executionInfo":{"status":"ok","timestamp":1667388884159,"user_tz":0,"elapsed":2641621,"user":{"displayName":"Tony Cash","userId":"15357384119899770783"}},"outputId":"93fff492-d41c-405f-b134-7bf585612a04"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 225, 128)          66560     \n","                                                                 \n"," dropout (Dropout)           (None, 225, 128)          0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 225, 128)          131584    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 225, 128)          0         \n","                                                                 \n"," lstm_2 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 329,857\n","Trainable params: 329,857\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/25\n","79/79 [==============================] - 117s 1s/step - loss: 0.0632 - val_loss: 0.0443\n","Epoch 2/25\n","79/79 [==============================] - 120s 2s/step - loss: 0.0454 - val_loss: 0.0449\n","Epoch 3/25\n","79/79 [==============================] - 115s 1s/step - loss: 0.0418 - val_loss: 0.0311\n","Epoch 4/25\n","79/79 [==============================] - 106s 1s/step - loss: 0.0197 - val_loss: 0.0064\n","Epoch 5/25\n","79/79 [==============================] - 107s 1s/step - loss: 0.0110 - val_loss: 0.0063\n","Epoch 6/25\n","79/79 [==============================] - 105s 1s/step - loss: 0.0091 - val_loss: 0.0058\n","Epoch 7/25\n","79/79 [==============================] - 106s 1s/step - loss: 0.0083 - val_loss: 0.0045\n","Epoch 8/25\n","79/79 [==============================] - 103s 1s/step - loss: 0.0074 - val_loss: 0.0038\n","Epoch 9/25\n","79/79 [==============================] - 105s 1s/step - loss: 0.0073 - val_loss: 0.0043\n","Epoch 10/25\n","79/79 [==============================] - 104s 1s/step - loss: 0.0072 - val_loss: 0.0037\n","Epoch 11/25\n","79/79 [==============================] - 105s 1s/step - loss: 0.0067 - val_loss: 0.0041\n","Epoch 12/25\n","79/79 [==============================] - 102s 1s/step - loss: 0.0066 - val_loss: 0.0044\n","Epoch 13/25\n","79/79 [==============================] - 104s 1s/step - loss: 0.0063 - val_loss: 0.0040\n","Epoch 14/25\n","79/79 [==============================] - 104s 1s/step - loss: 0.0061 - val_loss: 0.0041\n","Epoch 15/25\n","79/79 [==============================] - 105s 1s/step - loss: 0.0060 - val_loss: 0.0038\n","Epoch 16/25\n","79/79 [==============================] - 103s 1s/step - loss: 0.0059 - val_loss: 0.0037\n","Epoch 17/25\n","79/79 [==============================] - 104s 1s/step - loss: 0.0058 - val_loss: 0.0039\n","Epoch 18/25\n","79/79 [==============================] - 104s 1s/step - loss: 0.0059 - val_loss: 0.0041\n","Epoch 19/25\n","79/79 [==============================] - 104s 1s/step - loss: 0.0063 - val_loss: 0.0038\n","Epoch 20/25\n","79/79 [==============================] - 105s 1s/step - loss: 0.0060 - val_loss: 0.0039\n","Epoch 21/25\n","79/79 [==============================] - 105s 1s/step - loss: 0.0056 - val_loss: 0.0040\n","Epoch 22/25\n","79/79 [==============================] - 103s 1s/step - loss: 0.0056 - val_loss: 0.0046\n","Epoch 23/25\n","79/79 [==============================] - 104s 1s/step - loss: 0.0055 - val_loss: 0.0040\n","Epoch 24/25\n","79/79 [==============================] - 100s 1s/step - loss: 0.0055 - val_loss: 0.0046\n","Epoch 25/25\n","79/79 [==============================] - 101s 1s/step - loss: 0.0054 - val_loss: 0.0055\n"]}]},{"cell_type":"markdown","source":["Prediction\n"],"metadata":{"id":"qCYTua_m7TqF"}},{"cell_type":"code","source":["actual_temp = test[\"Avg_Temp\"].values\n","total_temp = pd.concat((train[\"Avg_Temp\"], test[\"Avg_Temp\"]), axis=0)\n","model_inputs = total_temp[len(total_temp)-prediction_days:].values\n","model_inputs = scaler.transform(model_inputs)\n","x_test = []\n","for x in range(prediction_days, len(model_inputs)):\n","  x_test.append(model_inputs[x-prediction_days:x, 0])\n","x_test = np.array(x_test)\n","x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n","\n","pred = model.predict(x_test)\n","pred = scaler.inverse_transform(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":798},"id":"gd4wGNgn7TDN","executionInfo":{"status":"error","timestamp":1667389571431,"user_tz":0,"elapsed":328,"user":{"displayName":"Tony Cash","userId":"15357384119899770783"}},"outputId":"db20bab2-a878-428a-bee8-d932c63edc0d"},"execution_count":10,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-6ca0a52be904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtotal_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Avg_Temp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Avg_Temp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprediction_days\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_days\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         )\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 )\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[14.45  15.59  19.629 21.649 25.963 26.419 28.    28.234 26.966 24.358\n 17.997 14.828 14.394 15.352 16.393 20.213 25.252 26.461 28.11  27.347\n 26.652 22.842 19.183 16.378 15.815 18.463 21.829 20.547 24.123 26.26\n 27.99  27.878 26.999 22.939 18.535 15.751 16.496 16.164 17.293 21.247\n 25.445 29.012 28.873 28.509 27.277 24.575 21.689 18.883 16.753 17.202\n 17.598 22.785 24.015 26.49  28.105 28.63  26.551 23.456 19.683 15.995\n 15.41  16.542 20.266 20.41  25.425 27.118 28.1   27.945 26.882 22.302\n 18.495 14.529 12.435 18.934 18.362 21.453 24.176 27.023 27.656 27.844\n 25.852 22.67  20.808 18.672 15.903 15.978 19.826 23.44  25.21  26.729\n 27.815 27.722 27.783 25.218 18.371 15.179 12.145 16.907 21.46  21.188\n 25.966 27.049 27.722 27.619 26.6   23.768 21.243 14.48  14.581 15.853\n 19.316 20.211 24.929 27.709 28.033 27.793 27.051 24.255 20.644 15.316\n 16.2   16.577 17.772 19.765 23.921 26.917 28.758 28.827 27.611 23.627\n 20.458 14.833 16.613 15.264 18.733 22.754 24.584 27.185 28.078 28.545\n 26.842 23.018 18.504 18.584 16.958 15.241 19.588 20.551 24.179 26.89\n 28.241 29.073 27.378 25.098 19.182 18.678 15.325 17.833 18.702 21.177\n 24.952 27.375 27.634 27.793 27.031 22.612 17.389 17.456 14.817 14.87\n 18.955 21.27  24.974 27.954 27.993 28.199 27.408 24.627 19.761 16.671\n 12.205 12.291 15.706 21.277 26.023 28.673 28.876 28.944 27.702 23.117\n 19.379 11.175 13.571 17.097 19.662 23.127 24.908 27.987 28.406 29.074\n 27.038 22.167 20.093 18.021 16.006 18.432 21.678 22.084 25.55  26.598\n 28.145 27.884 26.868 23.548 17.769 17.608 18.435 17.152 15.533 22.167\n 23.576 27.432 27.327 28.188 27.493].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."]}]},{"cell_type":"markdown","source":["ACTIVITY\n"],"metadata":{"id":"PqlUh7E798o5"}},{"cell_type":"code","source":[],"metadata":{"id":"N3aoq_YO98Xc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dr. Gu code solution:\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import datetime as dt\n","import io\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, LSTM\n","\n","# Load Data\n","florida = pd.read_csv(io.BytesIO(uploaded['florida.csv']))\n","florida.head()\n","florida.tail(5)\n","florida[\"Date\"] = pd.to_datetime(florida[\"Date\"]) # transfer to dataframe\n","\n","florida = florida[[\"Date\", \"Avg_Temp\"]] # extract the columns we are going to use\n","# florida = florida[\"Avg_Temp\"].resample('MS').mean()\n","florida = florida.fillna(florida.bfill()) # fill missing values\n","florida.columns = ['Date', 'Avg_Temp'] # define column name\n","\n","train = florida[:-225] # define train set\n","len(train)\n","test = florida[-225:] # define test set\n","len(test)\n","train_dates = pd.to_datetime(train['Date'])\n","test_dates  = pd.to_datetime(test['Date'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"Dk6k80El-OEN","executionInfo":{"status":"error","timestamp":1667389578386,"user_tz":0,"elapsed":296,"user":{"displayName":"Tony Cash","userId":"15357384119899770783"}},"outputId":"09ce86bb-10c8-4d97-a3a2-ebe67a5f6896"},"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-516de37672cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mflorida\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'florida.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mflorida\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mflorida\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'uploaded' is not defined"]}]},{"cell_type":"code","source":["test"],"metadata":{"id":"Of0oSEuS-kho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = MinMaxScaler(feature_range=(0,1))\n","scaled_data = scaler.fit_transform(train['Avg_Temp'].values.reshape(-1,1)) # normalise\n","\n","prediction_days = 225\n","\n","x_train = []\n","y_train = []\n","\n","# generate data samples (for each sample, 225 days as input, next day as output)\n","for x in range(prediction_days, len(scaled_data)):\n","    x_train.append(scaled_data[x-prediction_days:x, 0])\n","    y_train.append(scaled_data[x, 0])\n","\n","\n","x_train, y_train = np.array(x_train), np.array(y_train)\n","x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"],"metadata":{"id":"6r06tonv-lMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"id":"6vx6mRyc-nlf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train.shape"],"metadata":{"id":"VjNUaqej-pSf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# designe the network\n","\n","model = Sequential()\n","\n","model.add(LSTM(units =128, activation='relu', return_sequences=True, input_shape = (x_train.shape[1],1)))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units =128, activation='relu', return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units =128, activation='relu', return_sequences=False))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=1)) # Prediction of the next value"],"metadata":{"id":"4rPXcCCc-q8n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='mean_squared_error')\n","model.summary()\n","\n","history = model.fit(x_train, y_train, epochs = 25, batch_size=32, validation_split=0.1)"],"metadata":{"id":"RLjbswIw-tt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["actual_temp = test['Avg_Temp'].values\n","total_temp = pd.concat((train['Avg_Temp'], test['Avg_Temp']),axis=0)\n","\n","model_inputs = total_temp[len(total_temp)-len(test)-prediction_days:].values\n","model_inputs = model_inputs.reshape(-1,1)\n","model_inputs = scaler.transform(model_inputs)\n","\n","\n","# Make Predictions on Test Data\n","x_test = []\n","\n","for x in range(prediction_days, len(model_inputs)):\n","    x_test.append(model_inputs[x-prediction_days:x, 0])\n","\n","x_test = np.array(x_test)\n","x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n","\n","pred = model.predict(x_test)\n","pred = scaler.inverse_transform(pred)"],"metadata":{"id":"mH9KWO8L-vwh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","mean_absolute_error(test['Avg_Temp'], pred)"],"metadata":{"id":"Xd8gD_v4-zYu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Visualization ###\n","#####################\n","pred_ = pd.DataFrame(test['Date'])\n","pred_['Avg_Temp'] = pred\n","pred_[\"Date\"] = pd.to_datetime(pred_[\"Date\"])\n","\n","pred_\n","original = florida.loc[florida['Date'] >= '1990-01-01']\n","\n","import seaborn as sns\n","sns.lineplot(original['Date'], original['Avg_Temp'])\n","sns.lineplot(pred_['Date'], pred_['Avg_Temp'])\n","plt.show()"],"metadata":{"id":"ATK2ftfn-1Qm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xMkVC2Ib-35_"},"execution_count":null,"outputs":[]}]}